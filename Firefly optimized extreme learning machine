import numpy as np
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Define the Firefly Optimization algorithm
def firefly_optimization(X, y, n_fireflies, max_iterations):
    # Initialize fireflies randomly
    fireflies = np.random.rand(n_fireflies, X.shape[1])
    
    # Define the fitness function
    def fitness(firefly):
        predictions = np.dot(firefly, weights) + biases
        return -mean_squared_error(y, predictions)
    
    # Main optimization loop
    for iteration in range(max_iterations):
        for i in range(n_fireflies):
            for j in range(n_fireflies):
                if fitness(fireflies[i]) < fitness(fireflies[j]):
                    # Move the firefly towards the brighter one
                    beta0 = 1.0  # Attraction coefficient
                    beta = beta0 * np.exp(-0.2 * (iteration / max_iterations))
                    epsilon = np.random.uniform(-1, 1, size=X.shape[1])
                    fireflies[i] += beta * (fireflies[j] - fireflies[i]) + 0.01 * epsilon
        
    # Return the best firefly (solution)
    best_firefly = fireflies[np.argmax([fitness(firefly) for firefly in fireflies])]
    return best_firefly

# Load your dataset
X = ...
y = ...

# Normalize the input features
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the weights and biases randomly
weights = np.random.rand(X_train.shape[1])
biases = np.random.rand()

# Perform Firefly Optimization to tune the weights and biases
optimized_params = firefly_optimization(X_train, y_train, n_fireflies=20, max_iterations=100)

# Set the optimized parameters to the weights and biases
weights = optimized_params[:-1]
biases = optimized_params[-1]

# Predict the output using the optimized weights and biases
predictions = np.dot(X_test, weights) + biases

# Calculate the evaluation metrics
mse = mean_squared_error(y_test, predictions)
rmse = np.sqrt(mse)
r2 = 1 - (mse / np.var(y_test))

# Print the evaluation metrics
print("Root Mean Squared Error (RMSE):", rmse)
print("Coefficient of Determination (R2):", r2)
